---
title: "Week 3 - Homework"
author: "STAT 420, Summer 2021, Ashutosh Agarwal (aa61)"
date: '06/06/2021'
output:
  html_document: 
    theme: readable
    toc: yes  
  pdf_document: default
urlcolor: cyan
---


# Directions

Students are encouraged to work together on homework. However, sharing, copying or providing any part of a homework solution or code is an infraction of the University's rules on Academic Integrity. Any violation will be punished as severely as possible.

- Be sure to remove this section if you use this `.Rmd` file as a template.
- You may leave the questions in your final document.

***

## Exercise 1 (Using `lm` for Inference)

For this exercise we will use the `cats` dataset from the `MASS` package. You should use `?cats` to learn about the background of this dataset.

**(a)** Fit the following simple linear regression model in `R`. Use heart weight as the response and body weight as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `cat_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

**Answer**

- **Null hypothesis:** $H_0$: $\beta_1$ = 0 i.e. There is no significant linear relationship between predictor (body weight) and response (Heart weight).

- **Alternate hypothesis:** $H_1$: $\beta_1$ $\neq$ 0 i.e. There is significant linear relationship between body weight and heart weight.

```{r warning=FALSE}
library("MASS")
cats_model = lm(Hwt ~ Bwt, data = cats)
```

- **$t-Value$**

```{r}
summary(cats_model)$coefficients["Bwt", "t value"]
```

- **$p-value$**

```{r}
p_value = summary(cats_model)$coefficients["Bwt", "Pr(>|t|)"]
p_value
```

With this extremely low p-value we can reject null hypotheses at any reasonable value of $\alpha$ .

- **Testing null hypotheses at $\alpha = 0.05$**

  There are two ways of testing this:

    - **Using value of $\alpha$ and $p-value$**
      We can see that $\alpha$ = $0.05$ is greater than p-value (`r p_value`). Therefore we can reject null hypotheses.

    - **Using confidence interval.**
```{r}
confint(object = cats_model, parm = "Bwt", level = 0.95)
```

Clearly $0$ is not within this range. We can reject null hypotheses for $\alpha = 0.05$

- **Conclusion** - For cats dataset, with extremely low p-value for $H_0$ = $0$ vs $H_1$ $\neq$ $0$ we can reject null hypotheses for any reasonable value of $\alpha$

In other words we can say there is significant linear relationship between Body weight and heart weight of cats.

**(b)** Calculate a 95% confidence interval for $\beta_1$. Give an interpretation of the interval in the context of the problem.

**Answer**

```{r}
cInt = confint(object = cats_model, parm = "Bwt", level = 0.95)
cInt
```

This means we are 95% confident that the true change in mean heart weight for an increase in body weight of one kg is between `r cInt[1]` and `r cInt[2]` 


**(c)** Calculate a 90% confidence interval for $\beta_0$. Give an interpretation of the interval in the context of the problem.

**Answer**

```{r}
cInt = confint(object = cats_model, parm = "(Intercept)", level = 0.90)
cInt
```

This means we are 90% confident that the true value of heart weight when body weight is zero kg is between `r cInt[1]` and `r cInt[2]` 

**(d)** Use a 90% confidence interval to estimate the mean heart weight for body weights of 2.1 and 2.8 kilograms. Which of the two intervals is wider? Why?

```{r}
newdata = data.frame(Bwt = c(2.1, 2.8))
p = predict(object = cats_model, newdata = newdata, level = 0.9, interval = c("confidence"))
range = data.frame(range = c(p[1, "upr"] - p [1, "lwr"], p[2, "upr"] - p [2, "lwr"]))
cbind(p, range = range, Bwt = newdata)
```

Interval at 2.1 kg is wider than 2.8 kg. This is because 2.1 kg is further from  the mean (of Bwt) of entire dataset `r mean(cats$Bwt)` than 2.8 kg. And we saw in the lecture that confidence and prediction intervals are wider away from mean.


**(e)** Use a 90% prediction interval to predict the heart weight for body weights of 2.8 and 4.2 kilograms.

```{r}
newdata = data.frame(Bwt = c(2.8, 4.2))
p = predict(object = cats_model, newdata = newdata, level = 0.9, interval = c("prediction"))
cbind(p, Bwt = newdata)

```


**(f)** Create a scatterplot of the data. Add the regression line, 95% confidence bands, and 95% prediction bands.

```{r}
beta_0_hat = cats_model$coefficients["(Intercept)"]
beta_1_hat = cats_model$coefficients["Bwt"]

newdata = data.frame(Bwt = seq(min(cats$Bwt), max(cats$Bwt), 0.1))
conf = predict(cats_model, newdata = newdata, level = 0.95, interval = c("confidence"))
pred = predict(cats_model, newdata = newdata, level = 0.95, interval = c("prediction"))

plot(Hwt ~ Bwt,
     data = cats,
     xlab = "Body weight (kgs)",
     ylab = "Heart weight (gm)",
     main = "Regression and intervals",
     col = "grey",
     pch = 20,
     ylim = c(min(pred), max(pred)))

abline(beta_0_hat, beta_1_hat, col = "Orange", lwd = 5, lty = 1)
lines(newdata$Bwt, conf[,"lwr"], col = "blue", lwd = 3,  lty = 2)
lines(newdata$Bwt, conf[,"upr"], col = "blue", lwd = 3,  lty = 2)
lines(newdata$Bwt, pred[,"lwr"], col = "blue", lwd = 3,  lty = 3)
lines(newdata$Bwt, pred[,"upr"], col = "blue", lwd = 3,  lty = 3)
legend("topleft", legend=c("Regression", "Confidence interval", "Prediction interval"), col=c("orange", "blue", "blue"), lty = 1:3, lwd = c(5,3,3))
```


**(g)** Use a $t$ test to test:

- $H_0: \beta_1 = 4$
- $H_1: \beta_1 \neq 4$

Report the following:

- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

**$t-value$**
```{r}
beta_hat_1 = summary(cats_model)$coefficients["Bwt", "Estimate"]
beta_1 = 4

# Standard error of beta_1 is calculated as "(Residual standard error) / sqrt(Sxx)". Here RSE is std dev of errors in predictions.
# This value is also available in summary of model against Estimated of Bwt
se_beta_1 = summary(cats_model)$coefficients["Bwt", "Std. Error"]
t_value = (beta_hat_1 - beta_1)/ se_beta_1
t_value
```

**$p-value$**

```{r}
p_value = 2 * pt(t_value, df = length(cats$Bwt) - 2, lower.tail = FALSE)
p_value
```

**A statistical decision at $\alpha = 0.05$**

Since value of $\alpha$ ($0.5$) is greater than p-value (`r p_value`) we fail to reject null hypothesis. This means there is significant linear relationship between Body weight and Heart weight.

***

## Exercise 2 (More `lm` for Inference)

For this exercise we will use the `Ozone` dataset from the `mlbench` package. You should use `?Ozone` to learn about the background of this dataset. You may need to install the `mlbench` package. If you do so, do not include code to install the package in your `R` Markdown document.

For simplicity, we will re-perform the data cleaning done in the previous homework.

```{r}
data(Ozone, package = "mlbench")
Ozone = Ozone[, c(4, 6, 7, 8)]
colnames(Ozone) = c("ozone", "wind", "humidity", "temp")
Ozone = Ozone[complete.cases(Ozone), ]
```

**(a)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and wind speed as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_wind_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

**Answer**

- **Null hypothesis:** $H_0$: $\beta_1$ = $0$ i.e. There is no significant linear relationship between predictor (wind speed) and response (Ozone).

- **Alternate hypothesis:** $H_1$: $\beta_1$ $\neq$ $0$ i.e. There is significant linear relationship between wind speed and Ozone.

```{r warning=FALSE}
ozone_wind_model = lm(ozone ~ wind, data = Ozone)
```

- **$t-Value$**

```{r}
summary(ozone_wind_model)$coefficients["wind", "t value"]
```

- **$p-value$**

```{r}
summary(ozone_wind_model)$coefficients["wind", "Pr(>|t|)"]
```

- **Testing null hypothesis at $\alpha = 0.01$**

  There are two ways of testing this:

    - **Using value of $\alpha$ and $p-value$**
      We can see that $\alpha$ = $0.01$ is smaller than p-value. Therefore we fail to reject null hypothesis at $\alpha$ = $0.01$.

    - **Using confidence interval.**

```{r}
confint(object = ozone_wind_model, parm = "wind", level = 0.99)
```

Clearly $0$ is within this range. We fail to reject null hypothesis for $\alpha = 0.01$

- **Conclusion** - For Ozone dataset, we can say there is no significant linear relationship between wind speed and ozone.


**(b)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and temperature as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_temp_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

**Answer**

- **Null hypothesis:** $H_0$: $\beta_1$ = $0$ i.e. There is no significant linear relationship between predictor (temperature) and response (Ozone).

- **Alternate hypothesis:** $H_1$: $\beta_1$ $\neq$ $0$ i.e. There is significant linear relationship between temperature and Ozone.

```{r warning=FALSE}
ozone_temp_model = lm(ozone ~ temp, data = Ozone)
```

- **$t-Value$**

```{r}
summary(ozone_temp_model)$coefficients["temp", "t value"]
```

- **$p-value$**

```{r}
summary(ozone_temp_model)$coefficients["temp", "Pr(>|t|)"]
```

- **Testing null hypotheses at $\alpha = 0.01$**

  There are two ways of testing this:

    - **Using value of $\alpha$ and $p-value$**
      We can see that $\alpha$ = $0.01$ is greater than p-value. Therefore we reject null hypothesis at $\alpha$ = $0.01$.

    - **Using confidence interval.**

```{r}
confint(object = ozone_temp_model, parm = "temp", level = 0.99)
```

Clearly $0$ is not within this range. We reject null hypothesis for $\alpha = 0.01$

- **Conclusion** - For Ozone dataset, we can say there is significant linear relationship between temperature and ozone.

***

## Exercise 3 (Simulating Sampling Distributions)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = -5$
- $\beta_1 = 3.25$
- $\sigma^2 = 16$

We will use samples of size $n = 50$.

**(a)** Simulate this model $2000$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_0$ and $\hat{\beta}_1$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

**Answer**

```{r}
birthday = 18691002
set.seed(birthday)
n = 50
x = seq(0, 10, length = n)
```

```{r}
simCount = 2000
beta_0 = -5
beta_1 = 3.25
var = 16

beta_0_hats = rep(0, simCount)
beta_1_hats = rep(0, simCount)

for (i in 1:simCount){
  eps = rnorm(n = n, mean = 0, sd = sqrt(var))
  y = beta_0 + beta_1 * x + eps
  model = lm(y ~ x)
  
  beta_0_hats[i] = coef(model)[1]
  beta_1_hats[i] = coef(model)[2]
}
```


**(b)** Create a table that summarizes the results of the simulations. The table should have two columns, one for $\hat{\beta}_0$ and one for $\hat{\beta}_1$. The table should have four rows:

- A row for the true expected value given the known values of $x$
- A row for the mean of the simulated values
- A row for the true standard deviation given the known values of $x$
- A row for the standard deviation of the simulated values

**Answer**

```{r}
Sxx = sum((x - mean(x)) ^ 2)
var_true_beta_1_hats = var / Sxx
var_true_beta_0_hats = var * (1/ n + (mean(x) ^ 2)/ Sxx)

beta_0_summary = c(beta_0, mean(beta_0_hats), sqrt(var_true_beta_0_hats), sd(beta_0_hats))
beta_1_summary = c(beta_1, mean(beta_1_hats), sqrt(var_true_beta_1_hats), sd(beta_1_hats))
sim_summary = data.frame(beta_0_summary, beta_1_summary)

colnames(sim_summary) = c("beta_0_hat", "beta_1_hat")
rownames(sim_summary) = c("True expected", "Simulation mean", "True Std Dev", "Simulation Sd")

library(knitr)
kable(x = sim_summary, align = 'c')
```


**(c)** Plot two histograms side-by-side:

- A histogram of your simulated values for $\hat{\beta}_0$. Add the normal curve for the true sampling distribution of $\hat{\beta}_0$.
- A histogram of your simulated values for $\hat{\beta}_1$. Add the normal curve for the true sampling distribution of $\hat{\beta}_1$.

**Answer**

```{r}
par(mfrow=c(1,2))
hist(beta_0_hats, main = "", prob = TRUE, xlab = expression(hat(beta)[0]))
curve(dnorm(x, mean = beta_0, sd = sqrt(var_true_beta_0_hats)), col = "darkorange", add = TRUE, lwd = 3)

hist(beta_1_hats, main = "", prob = TRUE, xlab = expression(hat(beta)[1]))
curve(dnorm(x, mean = beta_1, sd = sqrt(var_true_beta_1_hats)), col = "darkorange", add = TRUE, lwd = 3)
```


***

## Exercise 4 (Simulating Confidence Intervals)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = 5$
- $\beta_1 = 2$
- $\sigma^2 = 9$

We will use samples of size $n = 25$.

Our goal here is to use simulation to verify that the confidence intervals really do have their stated confidence level. Do **not** use the `confint()` function for this entire exercise.

**(a)** Simulate this model $2500$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_1$ and $s_e$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
birthday = 18691002
set.seed(birthday)
n = 25
x = seq(0, 2.5, length = n)
```

```{r}
simCount = 2500
beta_0 = 5
beta_1 = 2
var = 9

s_es = rep(0, simCount)
beta_1_hats = rep(0, simCount)

for (i in 1:simCount){
  eps = rnorm(n = n, mean = 0, sd = sqrt(var))
  y = beta_0 + beta_1 * x + eps
  model = lm(y ~ x)
  
  # Note for myself: Std error against predictor in summary(model) is "Residual error of predictions / sqrt(Sxx)"
  # Had we stored std error of beta_1 then we would not have to calculate Sxx in the conf interval calculation.
  # s_es[i] = summary(model)$coefficients["x", "Std. Error"]
  
  s_es[i] = summary(model)$sigma
  beta_1_hats[i] = coef(model)[2]
}
```

**(b)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 95% confidence interval. Store the lower limits in a vector `lower_95` and the upper limits in a vector `upper_95`. Some hints:

- You will need to use `qt()` to calculate the critical value, which will be the same for each interval.
- Remember that `x` is fixed, so $S_{xx}$ will be the same for each interval.
- You could, but do not need to write a `for` loop. Remember vectorized operations.

```{r}
Sxx = sum((x - mean(x))^2)
crit = qt(p = 0.975, df = n -2)

# Note: We actually did not need to use Sxx if we had stored standard errors of beta_1 instead
lower_95 = beta_1_hats - crit * s_es / sqrt(Sxx)
upper_95 = beta_1_hats + crit * s_es / sqrt(Sxx)
```

**(c)** What proportion of these intervals contains the true value of $\beta_1$?

**Answer:** 

```{r}
mean(beta_1 >= lower_95 & beta_1 <= upper_95)
```

**(d)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.05$?

**Answer:**

```{r}
1 - mean(0 >= lower_95 & 0 <= upper_95)
```

The proportion of simulations in which we will reject the null hypotheses is `r 1 - mean(0 >= lower_95 & 0 <= upper_95)` because $0$ is not included within 95% confidence interval of these simulations.


**(e)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 99% confidence interval. Store the lower limits in a vector `lower_99` and the upper limits in a vector `upper_99`.

```{r}
crit = qt(p = 0.995, df = n -2)

# Note: We actually did not need to use Sxx if we had stored standard errors of beta_1 instead
lower_99 = beta_1_hats - crit * s_es / sqrt(Sxx)
upper_99 = beta_1_hats + crit * s_es / sqrt(Sxx)
```

**(f)** What proportion of these intervals contains the true value of $\beta_1$?

```{r}
mean(beta_1 >= lower_99 & beta_1 <= upper_99)
```

**(g)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.01$?

**Answer:**

```{r}
1 - mean(0 >= lower_99 & 0 <= upper_99)
```

The proportion of simulations in which we will reject the null hypotheses is `r 1 - mean(0 >= lower_99 & 0 <= upper_99)` because $0$ is not included within 99% confidence interval of these simulations.

***

## Exercise 5 (Prediction Intervals "without" `predict`)

Write a function named `calc_pred_int` that performs calculates prediction intervals:

$$
\hat{y}(x) \pm t_{\alpha/2, n - 2} \cdot s_e\sqrt{1 + \frac{1}{n}+\frac{(x-\bar{x})^2}{S_{xx}}}.
$$

for the linear model

$$
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i.
$$

**(a)** Write this function. You may use the `predict()` function, but you may **not** supply a value for the `level` argument of `predict()`. (You can certainly use `predict()` any way you would like in order to check your work.)

The function should take three inputs:

- `model`, a model object that is the result of fitting the SLR model with `lm()`
- `newdata`, a data frame with a single observation (row)
    - This data frame will need to have a variable (column) with the same name as the data used to fit `model`.
- `level`, the level (0.90, 0.95, etc) for the interval with a default value of `0.95`

The function should return a named vector with three elements:

- `estimate`, the midpoint of the interval
- `lower`, the lower bound of the interval
- `upper`, the upper bound of the interval

```{r}
calc_pred_int = function(model, newdata, level = 0.95){
  n = nrow(model$model)
  
  y_hat = predict(model, newdata = newdata)
  crit = qt(p = level + (1 - level)/2, df = n - 2)
  
  predictorName = colnames(newdata)[1]
  
  # We cannot calculate mean over data frame, therefore we are converting it to a vector.
  # it would be simpler if we could use name of column directly
  x = as.double(model$model[,predictorName])
  
  Sxx = sum((x-mean(x))^2)
  
  # Note that we need standard error of x not beta_0 or beta_1
  s_e = summary(model)$sigma
  
  margin = crit * s_e * sqrt(1 + 1/ n + ((newdata - mean(x))^2) / Sxx)
  
  c(estimate = y_hat, lower = y_hat - margin, upper = y_hat + margin)
}
```


**(b)** After writing the function, run this code:

```{r, eval = TRUE}
newcat_1 = data.frame(Bwt = 4.0)
calc_pred_int(cats_model, newcat_1)
```

```{r}
# Verifying if output is consistent with Predict method

predict(object = cats_model, newdata = newcat_1, level = 0.95, interval = c("prediction"))
```


**(c)** After writing the function, run this code:

```{r, eval = TRUE}
newcat_2 = data.frame(Bwt = 3.3)
calc_pred_int(cats_model, newcat_2, level = 0.90)
```

```{r}
# Verifying if output is consistent with Predict method

predict(object = cats_model, newdata = newcat_2, level = 0.90, interval = c("prediction"))
```
